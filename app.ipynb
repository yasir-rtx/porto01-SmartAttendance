{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66f85140",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress TensorFlow warnings and info messages\n",
    "from silence_tensorflow import silence_tensorflow\n",
    "silence_tensorflow()\n",
    "\n",
    "import os\n",
    "os.environ[\"OPENCV_LOG_LEVEL\"]=\"SILENT\"\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "# Available backend options are: \"jax\", \"torch\", \"tensorflow\".\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "\n",
    "import cv2\n",
    "import time\n",
    "\n",
    "import os\n",
    "import json\n",
    "import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# from functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f99d9da8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7813af732e5b4e09929450f19dc91269",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@keras.saving.register_keras_serializable()\n",
    "def scaling(x, scale=1.0):\n",
    "\treturn x * scale\n",
    "# Load the FaceNet512 model from Hugging Face Hub\n",
    "# model = keras.saving.load_model(\n",
    "# \t\"hf://logasja/FaceNet512\",\n",
    "# \tcustom_objects={\"scaling\": scaling}\n",
    "# )\n",
    "\n",
    "# load the facenet128 model\n",
    "model = keras.saving.load_model(\"hf://logasja/FaceNet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0641241",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set camera\n",
    "def setCamera(index: int = 0, width: int = 1280, height: int = 720,):\n",
    "    cap = cv2.VideoCapture(index)\n",
    "    # Set the camera resolution (optional)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_WIDTH, width)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, height)\n",
    "    # Set the camera frame rate (optional)\n",
    "    # cap.set(cv2.CAP_PROP_FPS, fps)\n",
    "    return cap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4784a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get access to camera and configure it\n",
    "def getCamera(index: int = 0, max_attempt=5):\n",
    "    # Try to open external cameras\n",
    "    try:\n",
    "        while max_attempt:\n",
    "            print(f\"Opening Camera {index}...\")\n",
    "            cap = setCamera(index)\n",
    "            if not cap.isOpened():\n",
    "                print(f\"Camera {index} is not Available!\")\n",
    "                index += 1\n",
    "                max_attempt -= 1\n",
    "            else:\n",
    "                print(f\"Camera {index} is Available!\")\n",
    "                return cap\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while accessing the camera: {e}\")\n",
    "        exit()\n",
    "    # Open default camera if external cameras are not available\n",
    "    if not max_attempt:\n",
    "        print(\"Opening Default Camera\")\n",
    "        cap = setCamera(index=0)\n",
    "        if not cap.isOpened():\n",
    "            print(\"Default Camera is not Available!\")\n",
    "            raise SystemExit\n",
    "        return cap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e879008",
   "metadata": {},
   "outputs": [],
   "source": [
    "# face detection\n",
    "def detectFaces(frame, mode: str):\n",
    "    # Load the Haar Cascade classifier for face detection\n",
    "    HaarCascade = cv2.CascadeClassifier(cv2.samples.findFile(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\"))\n",
    "    # Detect faces in the image\n",
    "    faceGray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = HaarCascade.detectMultiScale(\n",
    "        image=faceGray,\n",
    "        scaleFactor=1.1,\n",
    "        minNeighbors=10,\n",
    "        minSize=(128, 128),\n",
    "        flags=cv2.CASCADE_SCALE_IMAGE,\n",
    "    )\n",
    "    \n",
    "    # Return the coordinates of the detected faces\n",
    "    if mode == \"single\":\n",
    "        if len(faces) > 0:\n",
    "            return [faces[0]], 1\n",
    "        else:\n",
    "            return [[0, 0, 0, 0]], 0 \n",
    "    elif mode == \"all\":\n",
    "        return faces, len(faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52981ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Render a rectangle around the detected faces\n",
    "def drawRectangle(x, y, width, height, frame, label=\"Face Detected\", distance=0.0):\n",
    "    # Calculate font size based on the width of the rectangle\n",
    "    # 0.002 is scale factor that determine font size\n",
    "    font_scale = width * 0.002\n",
    "    font_size = round(max(0.4, min(0.8, font_scale)), 2)\n",
    "    \n",
    "    # Draw a rectangle around the detected face\n",
    "    frame = cv2.rectangle(frame, (x, y), (x + width, y + height), (0, 255, 0), 1)\n",
    "    frame = cv2.rectangle(frame, (x,y-40), (x+width, y), (0, 255, 0), -2)\n",
    "    \n",
    "    # Draw a label above the rectangle\n",
    "    frame = cv2.putText(frame, label + ', ' + str(round(distance, 2)), (x+5, y-15), cv2.FONT_HERSHEY_SIMPLEX, font_size, (0, 0, 0), 1, cv2.LINE_AA)\n",
    "    \n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "a70e9eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save face images\n",
    "def saveFaceImage(label: str, face: list):\n",
    "    faces_path = os.path.join(\"./img/\", label)\n",
    "    \n",
    "    # check if path exist\n",
    "    if not os.path.exists(faces_path):\n",
    "        print(f\"Creating folder for new face: {label}\")\n",
    "        os.makedirs(faces_path)\n",
    "    else:\n",
    "        # print(f\"Folder for {label} already exists.\")\n",
    "        # print(\"Skipping save function...\")\n",
    "        # return\n",
    "        pass\n",
    "    \n",
    "    # counting the number of files in the directory\n",
    "    file_counter = len(os.listdir(faces_path)) + 1\n",
    "    \n",
    "    # generate filename and join it with face path\n",
    "    filename = os.path.join(faces_path, f\"{label}_{file_counter}.jpg\")\n",
    "    \n",
    "    # create dummy face\n",
    "    # face = np.random.randint(0, 256, size=(128, 128), dtype=np.uint8)\n",
    "    # print(face)\n",
    "    # cv2.imshow(\"Gambar Random Dibuat\", face)\n",
    "    # cv2.waitKey(0)\n",
    "    # cv2.destroyAllWindows()\n",
    "    \n",
    "    # save new face image\n",
    "    try:\n",
    "        face = cv2.cvtColor(face, cv2.COLOR_BGR2RGB)\n",
    "        cv2.imwrite(filename, face)\n",
    "        return f\"Face image saved as {filename}\"\n",
    "    \n",
    "    except Exception as e:\n",
    "        return f\"Gagal menyimpan gambar: {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "ef91fdb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File ./signatures.json already exists. Updating the file.\n",
      "\n",
      "Faces data is ready: (50, 160, 160, 3)\n",
      "Generating signature...\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step\n"
     ]
    }
   ],
   "source": [
    "# generate face signature\n",
    "def generateFaceSignature(label: str):\n",
    "    # check signature file\n",
    "    signatures_path = \"./signatures.json\"\n",
    "    if os.path.exists(signatures_path):\n",
    "        print(f\"File {signatures_path} already exists. Updating the file.\")\n",
    "        # Check if file is empty or invalid\n",
    "        with open(signatures_path, \"r+\") as f:\n",
    "            content = f.read().strip()\n",
    "            if not content:\n",
    "                f.seek(0)\n",
    "                json.dump({}, f, indent=4)\n",
    "                f.truncate()\n",
    "    else:\n",
    "        print(f\"File {signatures_path} does not exist. Creating a new file.\")\n",
    "        # Create an empty JSON file\n",
    "        json.dump({}, open(signatures_path, mode=\"w\"), indent=4)\n",
    "    \n",
    "    # prepare faces data\n",
    "    faces_path = os.path.join(\"./img/\", label)\n",
    "    faces_data = []\n",
    "    for file in os.listdir(faces_path):\n",
    "        face_path = os.path.join(faces_path, file)\n",
    "        face_img = cv2.imread(face_path)\n",
    "        face_img = cv2.resize(face_img, (160, 160))\n",
    "        face_img = (face_img - face_img.mean()) / face_img.std()\n",
    "        faces_data.append(face_img)\n",
    "    faces_data = np.array(faces_data)   # convert list of face to np.array\n",
    "    \n",
    "    # generate signature\n",
    "    print(f\"\\nFaces data is ready: {faces_data.shape}\")\n",
    "    print(\"Generating signature...\")\n",
    "    signature = model.predict(faces_data, batch_size=1)\n",
    "    \n",
    "    # combine 50 embedding to robust the signature\n",
    "    signature_mean = np.mean(signature, axis=0)\n",
    "    signature_median = np.median(signature, axis=0)\n",
    "    \n",
    "    # Convert all numpy arrays to lists for JSON serialization\n",
    "    signatures = []\n",
    "    signatures.append(signature.tolist())\n",
    "    signatures.append(signature_mean.tolist())\n",
    "    signatures.append(signature_median.tolist())\n",
    "    \n",
    "    # Load face signatures from database\n",
    "    data = json.load(open(signatures_path, mode=\"r\"))    \n",
    "    # Update the database with the new signature\n",
    "    data.update({label: signatures})\n",
    "    # Save the updated database to the file\n",
    "    json.dump(data, open(signatures_path, mode=\"w\"), indent=4)\n",
    "    \n",
    "    # signatures[0] -> 50 raw signatures\n",
    "    # signatures[1] -> mean signature\n",
    "    # signatures[2] -> median signature\n",
    "    \n",
    "    # return signatures\n",
    "\n",
    "generateFaceSignature(label=\"yasir\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450e592d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening Camera 1...\n",
      "Camera 1 is not Available!\n",
      "Opening Camera 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@4250.939] global cap_v4l.cpp:913 open VIDEOIO(V4L2:/dev/video1): can't open camera by index\n",
      "[ERROR:0@4251.134] global obsensor_uvc_stream_channel.cpp:158 getStreamChannelGroup Camera index out of range\n",
      "[ WARN:0@4251.139] global cap_v4l.cpp:913 open VIDEOIO(V4L2:/dev/video2): can't open camera by index\n",
      "[ERROR:0@4251.141] global obsensor_uvc_stream_channel.cpp:158 getStreamChannelGroup Camera index out of range\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Camera 2 is not Available!\n",
      "Opening Camera 3...\n",
      "Camera 3 is Available!\n",
      "Creating folder for new face: test\n"
     ]
    }
   ],
   "source": [
    "# Access camera\n",
    "cap = getCamera(index=1)\n",
    "\n",
    "# Initialize frame rate calculation\n",
    "prev_frame_time = 0\n",
    "new_frame_time = 0\n",
    "\n",
    "\n",
    "# Allow the camera to warm up\n",
    "time.sleep(2)\n",
    "\n",
    "# Check if the video capture has been initialized correctly\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open video device.\")\n",
    "    raise SystemExit\n",
    "\n",
    "# Streaming camera\n",
    "while cap.isOpened():\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    \n",
    "    # Read a frame from the camera\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    # Check if the frame was read correctly\n",
    "    if not ret:\n",
    "        print(\"Error: Could not read frame.\")\n",
    "        break\n",
    "    \n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)  # Convert the frame to BGR format\n",
    "    frame = cv2.flip(frame, 1)  # Flip the frame horizontally\n",
    "    \n",
    "    # Detect faces in the frame\n",
    "    faces,faces_count = detectFaces(frame, mode=\"single\")\n",
    "    \n",
    "    #  Loop through the detected faces\n",
    "    for x, y, width, height in faces:\n",
    "        # Draw rectangles around detected face\n",
    "        frame = drawRectangle(x, y, width, height, frame)\n",
    "        \n",
    "        # Extract the face region from the frame\n",
    "        face = frame[y:y+height, x:x+width]\n",
    "        # cv2.imshow(\"Face\", face) # Display the face region\n",
    "        \n",
    "        # save face image when pressing enter\n",
    "        if key == ord('\\r'):\n",
    "            saveFaceImage(label=\"test\", face=face)\n",
    "    \n",
    "    # FPS calculation\n",
    "    new_frame_time = time.time()\n",
    "    fps = 1 / (new_frame_time - prev_frame_time)\n",
    "    prev_frame_time = new_frame_time\n",
    "    \n",
    "    # Displaying information on the frame\n",
    "    frame_height = frame.shape[0]\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)  # Reveerse the frame to BGR format\n",
    "    cv2.putText(frame, f\"Detected Faces: {faces_count}\", (10, frame_height - 50), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1, cv2.LINE_AA) \n",
    "    cv2.putText(frame, f\"FPS: {int(fps)}\", (10, frame_height - 30), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1, cv2.LINE_AA)     # Display FPS on frame\n",
    "    cv2.putText(frame, f\"Shape: {frame.shape}\", (10, frame_height - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1, cv2.LINE_AA)    # Shape of the frame\n",
    "    \n",
    "    # Display the frame in a window\n",
    "    cv2.imshow(\"Camera Streaming\", frame)\n",
    "    time.sleep(0.01)    # Add a small delay to reduce CPU usage\n",
    "\n",
    "    # Wait for 1 ms and check if the 'q' key is pressed\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the video capture object and close all OpenCV windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
